
\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=15mm,bmargin=30mm,lmargin=30mm,rmargin=20mm}
%\usepackage{graphics}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{lipsum}
\usepackage{nomencl}
\makenomenclature
\usepackage{bibentry}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{gensymb}
\usepackage{refstyle}
\usepackage{setspace}
\usepackage{notoccite} %for sorting references
\usepackage{algorithm}
\usepackage{algorithmc}
\usepackage{program}
\usepackage{algpseudocode}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\graphicspath{ {images/} }
\onehalfspacing
\def\compressible{\textit{compressible}\hspace{0.1in}}
\def\sparse{\textit{sparse}\hspace{0.1in}}
\def\ksparse{\textit{k-sparse}\hspace{0.1in}}
\def\measurement{\textit{measurement}\hspace{0.1in}}
\def\x{$x$\hspace{0.1in}}
\def\y{$y$\hspace{0.1in}}
\def\cosamp{\textbf{CoSaMP}\hspace{0.1in}}
\makeatletter

\linespread{2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\spacefactor1000}

\makeatother

\begin{document}
\begin{titlepage}
\thispagestyle{empty}
\vspace*{0.7cm}
{\centering     
\large
{\Large\bf Compressed Sensing in Internet of Things}\\
\vspace{3cm}
\bf{Seminar Report}\\
\vspace{0.25cm}
\vspace{0.1cm}
\it
by \\
\vspace{.5cm}
\rm
{\large \bf {Nagma Samreen Khan}}\\
{\large \bf {153079030}}

\vspace{1cm}

{\it{under the guidance of}} \\
\vspace{.5cm}

\hspace{.05cm} {\large \bf {Prof. Kumar Appaiah}}\\
%\hspace{.05cm}
\vspace {0.5cm}
%\iitbseal\ \\

\begin{figure}[h] 
%\hspace{6cm}
%\vspace{5cm}
{\centering {\includegraphics[width=0.32\textwidth]{images/IITB_logo}}\par}
\end{figure} 

Department of Electrical Engineering \\ 
Indian Institute of Technology, Bombay\\ 
{\centering
\hspace{6.5cm}April 2016} 
}
\pagebreak 
\end{titlepage}

\begin{abstract}
The abstract goes here.
\end{abstract}
\section{Introduction}
  \subsection{Internet of Things}
  Internet of Things or commonly referred to as IoT defines a paradigm in which 'everyday' devices can be connected 
  together in a network and thus can communicate with each other over the Internet. Moreover the connected devices are equipped 
  with 'identifying', 'sensing' and 'processing' \cite{Whitmore-survey}
  capabilites which enable them to 
  acheive some objective or complete some assigned task. Nowadays IoT is widely used in applications like
  healthcare, utilities, transport, etc. The revolution in the field of IoT has enabled
  these devices to have interaction capabilites too i.e. they can be controlled, actuated and commanded.
  \cite{Gubbi-vision}. 
  \par The components of IoT broadly are Hardware, Software and Architecture. Hardware refers to the component/s
  or the device/s which constitue the system which has been designed to acheive some objective, Software refers roughly
  to the support which enables the devices in the system to exchange and process data inspite of their heterogeniety 
   %\cite{Whitmore-survey}
   and Architecture provides the specifications so that information transfer and processing
   and networking of devices can be done in a standard fashion  \cite{Whitmore-survey} \cite{Gubbi-vision}.
  \par In healthcare applications, IoT can be used to monitor a patient's health condtion over the Internet, and 
  in case of critical patients the sensors placed on the patient can transmit and make information available continuously
  to the doctors and patient's relatives which will lead to better monitoring and enable doctors to take timely action
  in case of emergencies. IoT has already made its mark in making 'smart homes' where sensors and actuators placed in 
  the house or building complex continuously monitor and control the resource consumption and also fulfil security needs.
  On a broader scale, IoT can be deployed to make 'smart cities' in which everything starting from traffic to the levels 
  of pollution can be monitored and controlled \cite{Whitmore-survey}. 
  \par Even in the industries IoT can be used for quality management, improving efficiency and tracking of goods. 
  In can be used in hazardous industries, say the mining industry, to improve the safety level
  by monitoring the condition inside the mine via sensors and continuously process the data to provide better disaster
  management and in-time warning systems. In transportation and logistics, the monitoring of movement of goods, say 
  using Radio Frequency Identification( RFID ) can be 
  made 'real-time' using IoT and thus providing better tracking \cite{Gubbi-vision}.
  \par These are just some examples of how IoT has affeced, is affecting and will affect our lives but one thing is clear
  that in the coming years IoT will lead to further betterment  in our lives through saving our time, money and resources.
  \subsection{Compressed Sensing}
  With increase in the number of connected devices around us, the amount of data transmitted over the Internet will naturally
  increase. Also with increase in the number of sensors, large amounts of data will be generated which will have to be 
  processed, stored and transmitted over the Internet in a timely fashion. So consumption of resources by the entire system
  will increase. This is where Compressed or Compressive Sensing comes in. 
  \par The simplest way to define Compressed Sensing is that we measure and transmit much less information i.e, \y 
  compared to what would have been actually measured by the sensors i.e, say \x and also \x can be reconstructed with a 
  small error at the receiver's end.
  This opens up a world of possibilities as it leads to saving time and resources and thus data transmission can be done
  much faster. The only prerequisite is that the data has to \textit{sparse} or \textit{compressible}
  in some transform domain. These concepts
  are defined mathematically in the next section, but here an example is presented to give a flavour of Compressed Sensing.
  Say we want to measure temperature at every point in a large room and for that purpose say we deploy 100 sensors distributed
  uniformly across the room. Now we know that temperature is a slowly varying quantity and thus will have mainly low
  frequency components. So if we take the Fourier Transform of the data then we can ignore the higher frequency coefficients
  and thus the measurements are compressible in Fourier Transform domain.
 
\section{Mathematical Background to Compressed Sensing}
\begin{defn}
 A vector \textit{x} $\in$ $\mathbb{R}^n$ is said to be \textit{k-sparse} if there are \textit{k} 
 non-zero coefficients in \textit{x}.
\end{defn}

\begin{defn}
 A vector \textit{x} $\in$ $\mathbb{R}^n$ is said to be \textit{compressible} if it is well-approximated by its
 \textit{k}-term \sparse approximation \textit{z} i.e. $\sigma_k$ is small where \cite{CS_book},
 \begin{equation}
%  \sigma_k = \inf_{\norm{z_0}_0 \leq k}
\sigma_k = \inf_{\|z_0\|_0 \leq k} \| x - z \|_p
\end{equation}
\end{defn}

\begin{defn}
 Support of a sparse vector \x i.e. $supp(x)$ is defined as,
 \begin{equation}
  supp(x)=\{i|x(i) \neq 0\}
 \end{equation}
 Note that for \ksparse signals $\|supp(x)\|_0 \leq k$.
\end{defn}

In this discussion we are assuming that \textit{x} is \sparse or \compressible in its original domain and no transform
is needed. We can make this assumption without loss of generalisation because any signal in $\mathbb{R}^n$ can be 
represented in terms on a basis matrix( assumed orthonormal ), say $\psi$ where $\psi_i$ vectors are its columns, so \x can be written as,
\begin{equation}
 x = \sum_{i=1}^{n} s_i \psi_i = \textbf{s} \psi 
\end{equation}
where \textit{s} $\in \mathbb{R}^n$. So \x and \textit{s} are considered equivalent \cite{Baraniuk-CS}. Also whenever
a vector is mentioned as \ksparse then either it actually is or it is \compressible and can be well approximated 
by its \ksparse representation.

\par Now suppose \textit{x}$\in$ $\mathbb{R}^n$ is the original data measured by the sensors and 
is known to be \ksparse then we don't measure \x directly but instead measure \y$\in$ $\mathbb{R}^m$, $m << n$ where,
\begin{equation}
 y = \phi x
\end{equation}
where $\phi$ is $m\times n$ matrix, called the \measurement matrix, and is required to satisfy the \textit{restricted
isometry property}( RIP)( see Def. ~\ref{def:RIP} ) and also it is required to be \textit{incoherent} with the basis matrix $\psi$ 
i.e, the rows of $\phi$ cannot sparsely represent the columns of $\psi$ \cite{Baraniuk-CS}.
\begin{defn}
 For $\phi$ to satisfy $2k$\textit{-restricted isometry property} ($2k$-RIP), the property states that 
 for any two vectors $x_1$ and $x_2$ and for
 a $\delta_{2k} \in (0,1)$, the following must hold,
  \begin{equation}
  (1 - \delta_{2k}) \leq \frac{\|\phi x_1-\phi x_2 \|_2}{\|x_1-x_2\|_2} \leq (1 + \delta_{2k}) \hspace{0.1in}
  where \hspace{0.1in} \|x_1\|_0, \|x_2\|_0 \leq k.
 \end{equation}
 or equivalently,
 \begin{equation}
  (1 - \delta_{2k}) \leq \frac{\|\phi x'\|_2}{\|\ x'\|_2} \leq (1 + \delta_{2k}) \hspace{0.1in}
  where \hspace{0.1in} x'=|x_1-x_2|.
 \end{equation}
 The smallest $\delta_{2k}$ for which the $2k$-RIP is satisfied is called the 
 $2k$th RIP constant of the matrix $\phi$ \cite{Needell-CoSaMP}.
 \label{def:RIP}
  \end{defn}
  It is evident that $x'$ will be $2k$-sparse as it is difference of two \ksparse signals.
  The RIP property means that the distance( here $l_2$ norm )between two \ksparse vectors is preserved
  during transformation with matrix $\phi$.
  
 \par It has been shown that a $m \times n$ matrix $\phi$ having iid entries from a Gaussian distribution
  possesess \textit{RIP} with high probability if $m \geq c\hspace{0.1in}log(\frac{n}{k})$, 
 where \textit{c} is small constant \cite{Baraniuk-CS}.

\section{Recovery Algorithms}
Given a measurement vector \y $\in \mathbb{R}^m$, which may be noisy, reconstructing the original \ksparse vector \x $\in \mathbb{R}^n$
requires searching over all $\binom{n}{k}$ subspaces. The challenge for the recovery algorithms is to identify 
which $k$ columns of $\phi$ span the subspace in which \y lies \cite{Dai-subspace}.
%As $m << n$, $\phi$ is spanning only \textit{m} dimensions,
%and the \textit{n-m} dimensions lie in its nullspace. So, there can be many vectors of the form $x'=x+r$, where $r$ belongs
%to null space of $\phi$, satisfying $\phi x' = y$. 
\subsection{CoSaMP}
In this discussion, we will be focussing on the \textit{Greedy Pursuit} algorithms, that tries to solve the problem
by acheiving the best performance for the particular instant with the hope that it will give an overall best performance.
On of the popular Greedy Pursuit Recovery algorithm for Compressed Sensing is \textit{Compressive Sampling
Matching Pursuit} algorithm or commonly known as \cosamp.

\subsubsection{Notation}
Before giving the mathematical background of \cosamp, certain notations have to be introduced \cite{Needell-CoSaMP}.
\begin{enumerate}
  \item For $x \in \mathbb{R}^n$ and $k$ a positive integer, $x_k$ implies retaining only the $k$ largest
values of \x and setting the rest equal to zero.
  
  \item For the set $T \subseteq {1,2,...n}$, $\phi_T$ refers to the column submatrix of $\phi$ where columns
  are chosen as per the values in set $T$.
  
  \item Pseudo-inverse of a matrix $A$ is defined as, 
  \begin{equation}
   A^\dagger= (A^\ast A)^{-1} A^\ast
  \end{equation}

  \item For $T \subseteq {1,2,...n}$, $x|_T$ is the restriction of \x to the set $T$, i.e. 
  \begin{equation}
   x|_T = 
   \begin{cases}
    x_i, & \text{if} \ i \in T\\
    0, & otherwise.
   \end{cases}
  \end{equation}

\end{enumerate}

\subsubsection{Algorithm Description}
The \cosamp algorithm is described as below:
\begin{enumerate}
 \item \textbf{Initialisation}:
 \begin{eqnarray}
  x^0 = 0 \\
  y_r = y \\
  i = 0 \\
 \end{eqnarray}
  where $x^i$ holds the approximation to \x at the \textit{i}-th iteration and $y_r$ is the \textit{residual}.
  
  \item Repeat these steps until \textbf{halting critereon} is true.
  \begin{enumerate}
   \item Form a proxy of \textit{residual} and then make it $2k$\sparse.
   \begin{eqnarray}
    x_{temp} = \phi^\ast y_r = \phi^\ast \phi x \\
    \Omega = supp(x_{temp \ 2k})
   \end{eqnarray}
   
  \item Merge supports $\Omega$ and supp($x^{i-1}$) for the \textit{i}-th iteration
  \begin{equation}
   T = \Omega \cup supp(x^{i-1})
  \end{equation}

  \item Solve a least squares problem to estimate \x, on the merged support.
  
  \end{enumerate}
  
\end{enumerate}

%Discuss DGS
\section{Verification of Recovery Algorithms through Simulation}
\section{Conclusion}
The conclusion goes here.

The authors would like to thank...\cite{Whitmore-survey} \cite{Huang-DGS}



\bibliographystyle{unsrt}%to make references appear in order of reference
\bibliography{seminar_report}


\end{document}


